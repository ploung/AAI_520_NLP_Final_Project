{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project – Agentic AI for Financial Research\n",
    "**Course:** AAI Program  \n",
    "**Team Members:** [Name 1], [Name 2], [Name 3]  \n",
    "**GitHub Repository:** [Insert link]\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "- Project overview  \n",
    "- Goals: Build an agentic AI that researches markets using autonomous agents  \n",
    "- Deliverables: Notebook (PDF/HTML), GitHub repo, documentation  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. System Architecture\n",
    "### 2.1 Agent Design\n",
    "- Orchestrator Agent  \n",
    "- Data Collection Agents (Yahoo Finance, NewsAPI, SEC)  \n",
    "- Analysis Agents (Sentiment, Fundamentals, Quant)  \n",
    "- Decision Agent  \n",
    "- Critic / Evaluator Agent  \n",
    "- Memory Module  \n",
    "\n",
    "### 2.2 Workflow Patterns\n",
    "- Prompt Chaining  \n",
    "- Routing  \n",
    "- Evaluator–Optimizer  \n",
    "\n",
    "*(Insert diagram of pipeline here)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Setup & Imports\n",
    "import yfinance as yf # Need to install yfinance package first by running: pip install yfinance\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "# import openai  # Uncomment if using LLM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc877eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(\"AAPL\", start=\"2025-09-18\", end=\"2025-09-18\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7483f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "print(\"Current date and time:\", now.strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent Functions\n",
    "We implement the four required capabilities:\n",
    "\n",
    "1. **Planning** – agent outlines research steps.  \n",
    "2. **Dynamic Tool Use** – APIs, datasets.  \n",
    "3. **Self-Reflection** – evaluation of outputs.  \n",
    "4. **Learning Across Runs** – simple memory store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Orchestrator planning steps for a ticker\n",
    "def plan_research(symbol):\n",
    "    steps = [\n",
    "        f\"Fetch price history for {symbol}\",\n",
    "        f\"Fetch latest news for {symbol}\",\n",
    "        \"Run sentiment analysis on news\",\n",
    "        \"Compute technical signals\",\n",
    "        \"Generate investment recommendation\",\n",
    "        \"Critique and refine output\"\n",
    "    ]\n",
    "    return steps\n",
    "\n",
    "plan_research(\"AAPL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Workflow Pattern 1 – Prompt Chaining\n",
    "Pipeline: News → Preprocess → Classify → Extract → Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Fetch and preprocess news\n",
    "news_sample = [\n",
    "    {\"title\": \"Apple beats earnings expectations\", \"text\": \"Apple reported higher than expected Q2 earnings...\"}\n",
    "]\n",
    "\n",
    "def preprocess_news(news):\n",
    "    return [n[\"text\"].lower() for n in news]\n",
    "\n",
    "processed = preprocess_news(news_sample)\n",
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment Classification (placeholder)\n",
    "def classify_sentiment(text):\n",
    "    return {\"sentiment\": \"positive\", \"score\": 0.8}\n",
    "\n",
    "classified = classify_sentiment(processed[0])\n",
    "classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity extraction (placeholder)\n",
    "def extract_entities(text):\n",
    "    return [\"Apple\", \"Q2 earnings\"]\n",
    "\n",
    "entities = extract_entities(processed[0])\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization (placeholder)\n",
    "def summarize(text):\n",
    "    return \"Apple beat Q2 earnings expectations, likely positive market reaction.\"\n",
    "\n",
    "summary = summarize(processed[0])\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Workflow Pattern 2 – Routing\n",
    "Route input to correct specialized agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(input_type, data):\n",
    "    if input_type == \"news\":\n",
    "        return classify_sentiment(data)\n",
    "    elif input_type == \"price\":\n",
    "        return \"Quant Agent output\"\n",
    "    elif input_type == \"filing\":\n",
    "        return \"Fundamentals Agent output\"\n",
    "    else:\n",
    "        return \"Unknown input type\"\n",
    "\n",
    "router(\"news\", \"Apple reports record revenue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Workflow Pattern 3 – Evaluator–Optimizer\n",
    "Generate analysis → Evaluate → Refine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple evaluator-optimizer loop\n",
    "def generate_analysis(symbol, signals):\n",
    "    return f\"Analysis for {symbol}: Buy based on signals {signals}\"\n",
    "\n",
    "def evaluate_analysis(analysis):\n",
    "    if \"Buy\" in analysis:\n",
    "        return \"Good, but lacks risk discussion\"\n",
    "    return \"Needs improvement\"\n",
    "\n",
    "def refine_analysis(analysis, feedback):\n",
    "    return analysis + f\" | Refined: {feedback}\"\n",
    "\n",
    "analysis = generate_analysis(\"AAPL\", {\"sentiment\": \"positive\", \"quant\": \"bullish\"})\n",
    "feedback = evaluate_analysis(analysis)\n",
    "refined = refine_analysis(analysis, feedback)\n",
    "refined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Demonstration – End-to-End Run\n",
    "- Choose a stock symbol (e.g., AAPL, TSLA, AMZN)  \n",
    "- Run through all agents and workflows  \n",
    "- Show final investment recommendation with rationale  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = \"AAPL\"\n",
    "\n",
    "steps = plan_research(symbol)\n",
    "print(\"Planned steps:\", steps)\n",
    "\n",
    "# Price data\n",
    "price_data = yf.download(symbol, period=\"6mo\", interval=\"1d\")\n",
    "price_data[\"Close\"].plot(title=f\"{symbol} Price Trend\")\n",
    "\n",
    "# Run agents (stub example)\n",
    "news_summary = summarize(\"Apple reported strong iPhone sales this quarter.\")\n",
    "sentiment = classify_sentiment(\"Apple reported strong iPhone sales this quarter.\")\n",
    "decision = generate_analysis(symbol, {\"sentiment\": sentiment, \"quant\": \"bullish\"})\n",
    "final_output = refine_analysis(decision, evaluate_analysis(decision))\n",
    "\n",
    "print(\"Final Investment Thesis:\", final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluation & Iteration\n",
    "- Example of system critiquing itself and re-running an agent  \n",
    "- Show before/after outputs  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "- What worked well  \n",
    "- Challenges  \n",
    "- Future improvements (better data sources, advanced models, memory persistence)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be04357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# If numpy is not installed, install it using pip\n",
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c1282",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b7f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7777be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dd1dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure\n",
    " from your online store in Germany. Unfortunately, when I opened the package,\n",
    " I discovered to my horror that I had been sent an action figure of Megatron\n",
    " instead! As a lifelong enemy of the Decepticons, I hope you can understand my\n",
    " dilemma. To resolve the issue, I demand an exchange of Megatron for the\n",
    " Optimus Prime figure I ordered. Enclosed are copies of my records concerning\n",
    " this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeedb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"text-classification\")\n",
    "outputs = classifier(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0de7381",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")\n",
    "outputs = ner_tagger(text)\n",
    "pd.DataFrame(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pipeline(\"question-answering\")\n",
    "question = \"What does the customer want?\"\n",
    "outputs = reader(question=question, context=text)\n",
    "pd.DataFrame([outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cbab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "outputs = summarizer(text, max_length=45, clean_up_tokenization_spaces=True)\n",
    "print(outputs[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddcd2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "fill_mask = pipeline(\"fill-mask\", model=\"metythorn/khmer-xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f828ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentencepiece\n",
    "result = fill_mask(\"ខ្ញុំចង់<mask>ភាសាខ្មែរ\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931d5cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "nlp = pipeline(\"fill-mask\", model=\"metythorn/khmer-xlm-roberta-base\")\n",
    "nlp(\"ខ្ញុំស្រលាញ់ <mask>។\")  # Example Khmer sentence with a masked token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline(\"translation_en_to_de\",\n",
    "model=\"Helsinki-NLP/opus-mt-en-de\")\n",
    "outputs = translator(text, clean_up_tokenization_spaces=True, min_length=100)\n",
    "print(outputs[0]['translation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e597b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    " generator = pipeline(\"text-generation\")\n",
    " response = \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\n",
    " prompt = text + \"\\n\\nCustomer service response:\\n\" + response\n",
    " outputs = generator(prompt, max_length=200)\n",
    " print(outputs[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2e5446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8b6245",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e037cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The error occurs because 'BertModel' is not a standalone pip package.\n",
    "# To use BertModel, install the 'transformers' library:\n",
    "!pip install transformers\n",
    "\n",
    "# Then import BertModel from transformers:\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d40279",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "# The error occurs because 'BertModel' is not a pip-installable package.\n",
    "# To use BertModel, install the 'transformers' library:\n",
    "# !pip install transformers\n",
    "\n",
    "# Then import BertModel from transformers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cf8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431cbdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from bertviz.neuron_view import show\n",
    "\n",
    "# To resolve the error, install bertviz first:\n",
    "!pip install bertviz\n",
    "\n",
    "# Then you can import show from bertviz.neuron_view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73205dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz.neuron_view import show\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24e59d51",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bertviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbertviz\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mneuron_view\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bertviz'"
     ]
    }
   ],
   "source": [
    "from bertviz.neuron_view import show"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
